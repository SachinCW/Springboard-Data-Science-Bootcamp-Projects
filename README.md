# Springboard Data Science Bootcamp Projects
This repository contains the projects I worked on as part of a 6 month intensive Data Science Bootcamp by Springboard.


The files in the repository and their brief decription is mentioned below - 

**api_data_wrangling_mini_project.ipynb :**

This project required pulling some data from the Qunadl API; Qaundl is currently the most widely used aggregator of financial market data. Equities data from the Frankfurt Stock Exhange (FSE) was the focus data. Analysis of the stock prices of a company called Carl Zeiss Meditec was performed in this project.
While there is a dedicated Python package for connecting to the Quandl API, I used the requests package for this project and instead of using Pandas which is a very handy package, I made use of Python's native data structures such as Lists and Dictionaries.

**Mini_Project_Data_Wrangling_Pandas.ipynb :**

In this project, I discovered some interesting data based on movie data from the IMDB.
This assignment helped reinforce the concepts of Data Wrangling and sharpen the skills in using Pandas. 

**Mini_Project_Wrangling_Json_Exercise.ipynb :**

This project dealt with data wrangling using JSON files as source and helped get familiar with packages for dealing with JSON.

**Mini_Project_SQL_with_Spark.ipynb :**

This project dealt with getting familiar with Spark SQL.
Spark SQL is a Spark module for structured data processing. It provides a programming abstraction called DataFrames and can also act as a distributed SQL query engine. It enables unmodified Hadoop Hive queries to run up to 100x faster on existing deployments and data. It also provides powerful integration with the rest of the Spark ecosystem (e.g., integrating SQL query processing with machine learning).
It brings native support for SQL to Spark and streamlines the process of querying data stored both in RDDs (Sparkâ€™s distributed datasets) and in external sources. Spark SQL conveniently blurs the lines between RDDs and relational tables. Unifying these powerful abstractions makes it easy for developers to intermix SQL commands querying external data with complex analytics, all within in a single application. 

**Mini_Project_Data_Wrangling_at_Scale_with_Spark.ipynb :**
Apache Spark is an excellent and ideal framework for wrangling, analyzing and modeling on structured and unstructured data - at scale! In this project, one of the most popular use-cases in the industry - log analytics was the focus area.

Typically, server logs are a very common data source in enterprises and often contain a gold mine of actionable insights and information. Log data comes from many sources in an enterprise, such as the web, client and compute servers, applications, user-generated content, flat files. They can be used for monitoring servers, improving business and customer intelligence, building recommendation systems, fraud detection, and much more.

Spark allows you to dump and store your logs in files on disk cheaply, while still providing rich APIs to perform data analysis at scale. This project showed how to use Apache Spark on real-world production logs from NASA and learn data wrangling and basic yet powerful techniques in exploratory data analysis.

**Mini_Project_Linear_Regression.ipynb :**
This project dealt with Linear Regression using Boston Housing Dataset. Predicting housing prices using the dataset provided was the goal of this project. Exploratory data analysis was conducted and the features having good correlation with the house price were choosen for predicion using Linear Regression

**Mini_Project_Logistic_Regression.ipynb :**
Goal of this project was to understand Logistic Regression Algorithm and its application.

**Mini_Project_Clustering.ipynb :**
Goal of this project was to apply k-means clustering algorithm to perform customer segmentation.

**Mini_Project_Tree_Based_Algorithms  :**
This project involved using Tree based algorithms such as Decision Tree Classifier to perform classification.

**Spark ML Mini-Project :** 
This project involved working on different Machine Learning Algorithms using Spark ML.
    
